{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "oiuLMFauCAmZ",
        "outputId": "49da81e6-70cc-47cf-a903-8dcccfb44d95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing clean, high-accuracy video...\n",
            "Processed 50 frames...\n",
            "Processed 100 frames...\n",
            "Processed 150 frames...\n",
            "Processed 200 frames...\n",
            "Processed 250 frames...\n",
            "Processed 300 frames...\n",
            "Processed 350 frames...\n",
            "Processed 400 frames...\n",
            "Processed 450 frames...\n",
            "Processed 500 frames...\n",
            "\n",
            "Success! Total frames processed: 538\n",
            "Video saved as: high_accuracy_congestion.mp4\n",
            "Initiating download to local machine...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_de417172-651d-497c-a613-053ff38c4434\", \"high_accuracy_congestion.mp4\", 12377175)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\"\"\"\n",
        "Highway Congestion and Speed Analysis\n",
        "-------------------------------------\n",
        "A classical computer vision pipeline for tracking vehicle speeds,\n",
        "detecting stopped vehicles, and analyzing highway congestion using\n",
        "Background Subtraction (MOG2) and Perspective Transformation (Homography).\n",
        "\n",
        "Author: Raj Antala\n",
        "\"\"\"\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# Safe import: Allows code to run in Google Colab OR locally on a PC\n",
        "try:\n",
        "    from google.colab import files\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================================\n",
        "INPUT_VIDEO_PATH = \"traffic_video.mp4\"\n",
        "OUTPUT_VIDEO_PATH = \"high_accuracy_congestion.mp4\"\n",
        "\n",
        "cap = cv2.VideoCapture(INPUT_VIDEO_PATH)\n",
        "if not cap.isOpened():\n",
        "    print(f\"Error: Cannot open video. Please check the file path.\")\n",
        "    exit()\n",
        "\n",
        "FRAME_WIDTH, FRAME_HEIGHT = 800, 600\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "if fps == 0: fps = 30\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(OUTPUT_VIDEO_PATH, fourcc, fps, (FRAME_WIDTH, FRAME_HEIGHT))\n",
        "\n",
        "# ============================================================================\n",
        "# 1. HOMOGRAPHY (BIRD'S EYE VIEW) SETUP\n",
        "# ============================================================================\n",
        "src_points = np.float32([[300, 250], [500, 250], [100, 550], [700, 550]])\n",
        "dst_points = np.float32([[0, 0], [400, 0], [0, 800], [400, 800]])\n",
        "perspective_matrix = cv2.getPerspectiveTransform(src_points, dst_points)\n",
        "\n",
        "# Assuming the mapped 800-pixel long stretch represents 40 meters of real highway.\n",
        "METERS_PER_PIXEL_WARPED = 40.0 / 800.0\n",
        "\n",
        "# ============================================================================\n",
        "# 2. CENTROID TRACKER CLASS\n",
        "# ============================================================================\n",
        "class CentroidTracker:\n",
        "    def __init__(self, max_disappeared=15):\n",
        "        self.next_id = 0\n",
        "        self.objects = {}\n",
        "        self.max_disappeared = max_disappeared\n",
        "\n",
        "    def register(self, centroid):\n",
        "        self.objects[self.next_id] = {'centroids': [centroid], 'speeds': [], 'disappeared': 0}\n",
        "        self.next_id += 1\n",
        "\n",
        "    def deregister(self, object_id):\n",
        "        del self.objects[object_id]\n",
        "\n",
        "    def update(self, rects):\n",
        "        if len(rects) == 0:\n",
        "            for obj_id in list(self.objects.keys()):\n",
        "                self.objects[obj_id]['disappeared'] += 1\n",
        "                if self.objects[obj_id]['disappeared'] > self.max_disappeared:\n",
        "                    self.deregister(obj_id)\n",
        "            return self.objects\n",
        "\n",
        "        input_centroids = np.zeros((len(rects), 2), dtype=\"int\")\n",
        "        for i, (x, y, w, h) in enumerate(rects):\n",
        "            input_centroids[i] = (int(x + w / 2.0), int(y + h / 2.0))\n",
        "\n",
        "        if len(self.objects) == 0:\n",
        "            for i in range(0, len(input_centroids)):\n",
        "                self.register(input_centroids[i])\n",
        "        else:\n",
        "            object_ids = list(self.objects.keys())\n",
        "            object_centroids = [self.objects[obj_id]['centroids'][-1] for obj_id in object_ids]\n",
        "\n",
        "            D = np.linalg.norm(np.array(object_centroids)[:, np.newaxis] - input_centroids, axis=2)\n",
        "            rows = D.min(axis=1).argsort()\n",
        "            cols = D.argmin(axis=1)[rows]\n",
        "\n",
        "            used_rows, used_cols = set(), set()\n",
        "\n",
        "            for row, col in zip(rows, cols):\n",
        "                if row in used_rows or col in used_cols: continue\n",
        "                if D[row, col] > 80: continue\n",
        "\n",
        "                obj_id = object_ids[row]\n",
        "                self.objects[obj_id]['centroids'].append(input_centroids[col])\n",
        "                self.objects[obj_id]['disappeared'] = 0\n",
        "\n",
        "                # INCREASED MEMORY: Keep the last 20 frames for smoother trajectory calculation\n",
        "                if len(self.objects[obj_id]['centroids']) > 20:\n",
        "                    self.objects[obj_id]['centroids'].pop(0)\n",
        "\n",
        "                used_rows.add(row)\n",
        "                used_cols.add(col)\n",
        "\n",
        "            unused_rows = set(range(0, D.shape[0])).difference(used_rows)\n",
        "            unused_cols = set(range(0, D.shape[1])).difference(used_cols)\n",
        "\n",
        "            for row in unused_rows:\n",
        "                obj_id = object_ids[row]\n",
        "                self.objects[obj_id]['disappeared'] += 1\n",
        "                if self.objects[obj_id]['disappeared'] > self.max_disappeared:\n",
        "                    self.deregister(obj_id)\n",
        "\n",
        "            for col in unused_cols:\n",
        "                self.register(input_centroids[col])\n",
        "\n",
        "        return self.objects\n",
        "\n",
        "# ============================================================================\n",
        "# 3. MAIN PROCESSING PIPELINE\n",
        "# ============================================================================\n",
        "mog = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=50, detectShadows=True)\n",
        "tracker = CentroidTracker()\n",
        "\n",
        "print(\"Processing clean, high-accuracy video...\")\n",
        "frame_count = 0\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret: break\n",
        "\n",
        "    frame_count += 1\n",
        "    if frame_count % 50 == 0: print(f\"Processed {frame_count} frames...\")\n",
        "\n",
        "    frame = cv2.resize(frame, (FRAME_WIDTH, FRAME_HEIGHT))\n",
        "\n",
        "    # ACCURACY UPGRADE 1: Strict Shadow Rejection\n",
        "    fgmask = mog.apply(frame, learningRate=0.002)\n",
        "    # Thresholding at 254 drops the gray shadows (127) and keeps only the solid white cars (255)\n",
        "    _, fgmask = cv2.threshold(fgmask, 254, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    kernel_open = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
        "    kernel_close = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 15))\n",
        "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel_open)\n",
        "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_CLOSE, kernel_close)\n",
        "\n",
        "    contours, _ = cv2.findContours(fgmask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    rects = []\n",
        "    for cnt in contours:\n",
        "        if cv2.contourArea(cnt) > 1200:\n",
        "            x, y, w, h = cv2.boundingRect(cnt)\n",
        "            rects.append((x, y, w, h))\n",
        "\n",
        "    tracked_objects = tracker.update(rects)\n",
        "\n",
        "    stopped_count = 0\n",
        "    active_speeds = []\n",
        "\n",
        "    for obj_id, data in tracked_objects.items():\n",
        "        if data['disappeared'] > 0: continue\n",
        "\n",
        "        centroids = data['centroids']\n",
        "        current_x, current_y = centroids[-1]\n",
        "\n",
        "        # ACCURACY UPGRADE 2: Calculate speed over a 15-frame gap to eliminate micro-jitter\n",
        "        if len(centroids) >= 15:\n",
        "            past_x, past_y = centroids[-15]\n",
        "\n",
        "            pts = np.array([[[past_x, past_y], [current_x, current_y]]], dtype=np.float32)\n",
        "            warped_pts = cv2.perspectiveTransform(pts, perspective_matrix)\n",
        "\n",
        "            w_past_x, w_past_y = warped_pts[0][0]\n",
        "            w_curr_x, w_curr_y = warped_pts[0][1]\n",
        "\n",
        "            distance_pixels = math.sqrt((w_curr_x - w_past_x)**2 + (w_curr_y - w_past_y)**2)\n",
        "            distance_meters = distance_pixels * METERS_PER_PIXEL_WARPED\n",
        "\n",
        "            time_seconds = 15.0 / fps\n",
        "            speed_mps = distance_meters / time_seconds\n",
        "            speed_kmph = speed_mps * 3.6\n",
        "\n",
        "            # Smooth the speed output using a larger moving average\n",
        "            data['speeds'].append(speed_kmph)\n",
        "            if len(data['speeds']) > 10: data['speeds'].pop(0)\n",
        "            avg_smoothed_speed = np.mean(data['speeds'])\n",
        "\n",
        "            if avg_smoothed_speed < 3.0:\n",
        "                cv2.circle(frame, (current_x, current_y), 5, (0, 0, 255), -1)\n",
        "                cv2.putText(frame, f\"ID {obj_id}: STOPPED\", (current_x - 20, current_y - 15),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
        "                stopped_count += 1\n",
        "            else:\n",
        "                cv2.circle(frame, (current_x, current_y), 5, (0, 255, 0), -1)\n",
        "                cv2.putText(frame, f\"ID {obj_id}: {avg_smoothed_speed:.1f} km/h\", (current_x - 20, current_y - 15),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "                active_speeds.append(avg_smoothed_speed)\n",
        "\n",
        "    # Dashboard overlay\n",
        "    highway_avg_speed = np.mean(active_speeds) if len(active_speeds) > 0 else 0\n",
        "    cv2.rectangle(frame, (10, 10), (380, 100), (0, 0, 0), -1)\n",
        "    cv2.putText(frame, f\"Avg Flow: {highway_avg_speed:.1f} km/h\", (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "    cv2.putText(frame, f\"Stopped Vehicles: {stopped_count}\", (20, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255) if stopped_count > 0 else (0, 255, 0), 2)\n",
        "\n",
        "    out.write(frame)\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "print(f\"\\nSuccess! Total frames processed: {frame_count}\")\n",
        "print(f\"Video saved as: {OUTPUT_VIDEO_PATH}\")\n",
        "\n",
        "# Triggers download only if running inside Google Colab\n",
        "if IN_COLAB:\n",
        "    print(\"Initiating download to local machine...\")\n",
        "    files.download(OUTPUT_VIDEO_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VIfltGgBM46R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}