{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAQEGVf-VL4u",
        "outputId": "62b6a445-3da5-4cf1-b80d-72f9fe83396e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading YOLOv8 model...\n",
            "Starting Deep Learning Tracking...\n",
            "Processed 50 frames...\n",
            "Processed 100 frames...\n",
            "Processed 150 frames...\n",
            "Processed 200 frames...\n",
            "Processed 250 frames...\n",
            "Processed 300 frames...\n",
            "Processed 350 frames...\n",
            "Processed 400 frames...\n",
            "\n",
            "Success! Total frames processed: 433\n",
            "Video temporarily saved to Colab as: yolo_basketball_tracking.mp4\n",
            "\n",
            "Mounting Google Drive to save the video safely...\n",
            "Mounted at /content/drive\n",
            "✅ Video successfully backed up to your Google Drive at: /content/drive/MyDrive/yolo_basketball_tracking.mp4\n",
            "You can now open drive.google.com to watch or download it!\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "AI-Powered Sports Broadcast Tracking Pipeline\n",
        "=============================================\n",
        "An advanced computer vision pipeline leveraging YOLOv8 for semantic \n",
        "object detection and ByteTrack for persistent multi-object tracking (MOT). \n",
        "\n",
        "This system renders professional broadcast-style visual overlays, including \n",
        "dynamic bounding boxes and fading historical trajectory trails. It is \n",
        "engineered for cloud execution environments (e.g., Google Colab), featuring \n",
        "automated Google Drive integration for seamless, high-volume video I/O.\n",
        "\n",
        "Author: Raj Antala\n",
        "\"\"\"\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "from collections import defaultdict\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Safe import for Google Colab environment\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================================\n",
        "INPUT_VIDEO_PATH = \"sports_video.mp4\"  # Make sure this matches your uploaded file\n",
        "OUTPUT_VIDEO_PATH = \"yolo_basketball_tracking.mp4\"\n",
        "TRAIL_LENGTH = 30\n",
        "\n",
        "def process_deep_tracking(input_path, output_path):\n",
        "    if not os.path.exists(input_path):\n",
        "        print(f\"Error: Could not find video at '{input_path}'\")\n",
        "        return\n",
        "\n",
        "    print(\"Loading YOLOv8 model...\")\n",
        "    # 'yolov8m.pt' is the medium model (Great balance of accuracy and speed)\n",
        "    model = YOLO('yolov8m.pt')\n",
        "\n",
        "    cap = cv2.VideoCapture(input_path)\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        print(\"Error: Could not read the first frame.\")\n",
        "        return\n",
        "\n",
        "    h, w = frame.shape[:2]\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    if fps == 0: fps = 30\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (w, h))\n",
        "\n",
        "    # Dictionary to store the historical center points for the broadcast trails\n",
        "    track_history = defaultdict(lambda: [])\n",
        "\n",
        "    print(\"Starting Deep Learning Tracking...\")\n",
        "    frame_count = 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret: break\n",
        "\n",
        "        frame_count += 1\n",
        "        if frame_count % 50 == 0:\n",
        "            print(f\"Processed {frame_count} frames...\")\n",
        "\n",
        "        # Run YOLOv8 tracking using ByteTrack\n",
        "        # classes=[0, 32] tells YOLO to ONLY look for 'person' (0) and 'sports ball' (32)\n",
        "        results = model.track(frame, persist=True, classes=[0, 32], tracker=\"bytetrack.yaml\", verbose=False)\n",
        "\n",
        "        # Ensure we actually detected something before trying to draw\n",
        "        if results[0].boxes is not None and results[0].boxes.id is not None:\n",
        "            boxes = results[0].boxes.xyxy.cpu().numpy()\n",
        "            track_ids = results[0].boxes.id.cpu().numpy().astype(int)\n",
        "            clss = results[0].boxes.cls.cpu().numpy().astype(int)\n",
        "\n",
        "            for box, track_id, cls in zip(boxes, track_ids, clss):\n",
        "                x1, y1, x2, y2 = map(int, box)\n",
        "\n",
        "                # Calculate the center bottom for players (looks better for foot trails), and true center for the ball\n",
        "                center_x = int((x1 + x2) / 2)\n",
        "                center_y = int(y2) if cls == 0 else int((y1 + y2) / 2)\n",
        "\n",
        "                # Set colors: Green for players, Orange for the ball\n",
        "                color = (0, 255, 0) if cls == 0 else (0, 165, 255)\n",
        "                label = f\"Player ID:{track_id}\" if cls == 0 else \"Ball\"\n",
        "\n",
        "                # Draw the bounding box and label\n",
        "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
        "                cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "                # Manage the Broadcast Trail History\n",
        "                track = track_history[track_id]\n",
        "                track.append((center_x, center_y))\n",
        "                if len(track) > TRAIL_LENGTH:\n",
        "                    track.pop(0)\n",
        "\n",
        "                # Draw the fading trail line\n",
        "                for i in range(1, len(track)):\n",
        "                    thickness = int(np.sqrt(64 / float(i + 1)) * 1.5)\n",
        "                    cv2.line(frame, track[i - 1], track[i], color, thickness)\n",
        "\n",
        "        # Dashboard UI Overlay\n",
        "        cv2.rectangle(frame, (10, 10), (550, 60), (0, 0, 0), -1)\n",
        "        cv2.putText(frame, \"AI TRACKING: YOLOv8 + ByteTrack\", (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
        "\n",
        "        out.write(frame)\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    print(f\"\\nSuccess! Total frames processed: {frame_count}\")\n",
        "    print(f\"Video temporarily saved to Colab as: {output_path}\")\n",
        "\n",
        "    # ========================================================================\n",
        "    # SAFE DOWNLOAD: COPY TO GOOGLE DRIVE\n",
        "    # ========================================================================\n",
        "    if IN_COLAB:\n",
        "        print(\"\\nMounting Google Drive to save the video safely...\")\n",
        "        drive.mount('/content/drive')\n",
        "\n",
        "        drive_path = f\"/content/drive/MyDrive/{output_path}\"\n",
        "        shutil.copy(output_path, drive_path)\n",
        "        print(f\"✅ Video successfully backed up to your Google Drive at: {drive_path}\")\n",
        "        print(\"You can now open drive.google.com to watch or download it!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    process_deep_tracking(INPUT_VIDEO_PATH, OUTPUT_VIDEO_PATH)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
